---
layout: homepage
---


<div class="row">
    <div class="col-md-7">
    <div class="block"></div>
      <p>Hi, I'm Meghana!</p>
      <p>I'm a B.Tech student in Computer Science and Engineering (Data Science) at VIT University, where I am advised by Dr. Joe Dhanith. My research focuses on large multimodal models for reasoning, spanning representation learning, domain generalization, and cross-modal intelligence. I'm broadly interested in how multimodal systems learn structure across vision, language, and neural signals, and how these models become more robust, interpretable, and adaptable.</p>
      <p>Currently, I'm a Machine Learning Intern at Nagasaki University advised by Dr. Muthu Subash Kavitha, where I work on improving implicit reasoning in large multimodal models. In parallel, I also work with Dr. Min Xu at the Xu Lab at Carnegie Mellon University on multimodal learning and medical AI, focusing on EEG–fNIRS fusion through state-space–based sequence modeling. Prior to this, I was a Machine Learning Intern at MulticoreWare Inc., where I worked on model optimization and post-training quantization, and on finetuning large-scale transformers for efficient deployment. I also interned at the Center for Neuroinformatics with Dr. Jeetashree Aparajita, where I worked on multimodal EEG–fNIRS learning fusion pipelines for cognitive stress analysis. I am a recipient of the Raman Research Award at VIT for my research contributions.</p>
      <p>Outside of academics, I love dancing. I lead major cultural events on campus and serve as President of VITc's dance club, where I choreograph, perform, and build spaces for artistic expression.</p>

      <p><a href="mailto:meghanaa.sunil@gmail.com"><u>email</u></a> / <a href="https://www.linkedin.com/in/meghana-sunil"><u>linkedin</u></a> / <a href="https://github.com/meghanaasunil"><u>github</u></a></p>
    </div>
    <div class="col-md-5">
        <img src="/assets/img/me/Meghana_sunil.jpeg?v=2" alt="Meghana Sunil" >
    </div>
</div>
<div>&nbsp;</div>

<h2>Selected Works</h2>

<div class="row" style="margin-bottom: 30px;">
    <div class="col-md-4">
        <img src="/assets/img/research/contrastive-learning.jpg" alt="Contrastive Learning Architecture" style="max-width: 100%; height: auto;">
    </div>
    <div class="col-md-8">
        <h4><strong>Contrastive Learning Under Domain Shift: Do Positive Pairs Help or Hurt Robustness?</strong></h4>
        <p><strong>Meghana Sunil</strong></p>
        <p><i>In Progress</i> | Advisor: Dr. Joe Dhanith</p>
        <p>Positive pairs aren't universally beneficial under domain shift—robustness increases only when their influence adapts to classifier confidence.</p>
        <p>[<a href="#">Paper</a>] [<a href="#">Code</a>]</p>
    </div>
</div>

<div class="row" style="margin-bottom: 30px;">
    <div class="col-md-4">
        <img src="/assets/img/research/eeg-fnirs.jpg" alt="EEG-fNIRS Architecture" style="max-width: 100%; height: auto;">
    </div>
    <div class="col-md-8">
        <h4><strong>Graph-Guided Cross-Modal Representation Learning of EEG–fNIRS via Spatio-Temporal Transformers for Stress Analysis</strong></h4>
        <p><strong>Meghana Sunil</strong></p>
        <p><i>Submitted: Computer Methods and Programs in Biomedicine</i> | Advisor: Dr. Jeetashree Aparajeeta</p>
        <p>Cross-modal stress classification benefits from explicitly modeling EEG–fNIRS structural dependencies, where graph-guided fusion yields more reliable spatio-temporal representations.</p>
        <p>[<a href="#">Paper</a>] [<a href="#">Code</a>]</p>
    </div>
</div>

<div class="row" style="margin-bottom: 30px;">
    <div class="col-md-4">
        <img src="/assets/img/research/rag-survey.jpg" alt="RAG Survey Architecture" style="max-width: 100%; height: auto;">
    </div>
    <div class="col-md-8">
        <h4><strong>Rethinking Knowledge Retrieval for Generation: A Survey on RAG Architectures and Applications</strong></h4>
        <p><strong>Meghana Sunil</strong></p>
        <p><i>Submitted: Artificial Intelligence Review</i> | Advisor: Dr. Joe Dhanith</p>
        <p>A systematic, comprehensive survey of RAG methods characterized through a four-tier architectural taxonomy, clarifying how retrieval design choices shape downstream generation behavior across applications.</p>
        <p>[<a href="#">Paper</a>] [<a href="#">Code</a>]</p>
    </div>
</div>

<p>For more research work, please visit my <a href="/research">Research</a> page.</p>

